\section{Convergence of the log-ODE method for rough differential equations}\label{apx:logodeconv}

In this section, we shall present ``rough path'' error estimates for the log-ODE method. In addition, we will discuss the case when the vector fields governing the rough differential equation are linear.
\medbreak

\begin{theorem}[Lemma 15 in \cite{logode2014estimate}]\label{thm:logODEthm}
Consider the rough differential equation
\begin{align}
dY_t & = f(Y_t)\,dX_t,\label{eq:RDE}\\
Y_0 & = \xi,\nonumber
\end{align}
where we make the following assumptions:
\begin{itemize}
\item $X$ is a geometric $p$-rough path in $\R^d$, that is $X : [0,T] \rightarrow T^{\floor{p}}(\R^d)$ is a continuous path in the tensor algebra
$T^{\floor{p}}(\R^d) := \R \oplus \R^d \oplus \big(\R^d\big)^{\otimes 2} \oplus \cdots \oplus \big(\R^d\big)^{\otimes \floor{p}}$ with increments
\begin{align}
X_{s,t} & = \Big(1, X_{s,t}^1, X_{s,t}^2, \cdots, X_{s,t}^{\floor{p}}\Big),\label{eq:roughpathincrements}\\
X_{s,t}^k & := \pi_k\big(X_{s,t}\big),\nonumber
\end{align}
where $\pi_k : T^{\floor{p}}\big(\R^d\big)\rightarrow \big(\R^d\big)^{\otimes k}$ is the projection map onto $\big(\R^d\big)^{\otimes k}$, such that there exists a sequence of
continuous finite variation paths $x_n : [0,T] \rightarrow \R^d$ whose truncated signatures converge to $X$ in the $p$-variation metric:
\begin{equation}
d_p\Big(S_{0,T}^{\floor{p}}(x_n), X\Big) \rightarrow 0,
\label{eq:rpconvege}
\end{equation}
as $n\rightarrow\infty$, where the $p$-variation between two continuous paths $Z^1$ and $Z^2$ in $T^{\floor{p}}(\R^d)$ is
\begin{equation}
d_p\big(Z_1, Z_2\big) := \max_{1\leq k\leq \floor{p}}\sup_{\D}\bigg(\sum_{t_i\in\D}\Big\|\pi_k\big(Z_{t_i, t_{i+1}}^1\big) - \pi_k\big(Z_{t_i, t_{i+1}}^2\big)\Big\|^p\bigg)^\frac{1}{p},
\label{eq:rpmetric}
\end{equation}
where the supremum is taken over all partitions $\D$ of $[0,T]$ and the norms $\|\cdot\|$ must satisfy (up to some constant)
\begin{equation}
\|a\otimes b\| \leq \|a\|\|b\|,\nonumber
\end{equation}
for $a\in(\R^d)^{\otimes n}$ and $b\in(\R^d)^{\otimes m}$. For example, we can take $\|\cdot\|$ to be the projective or injective tensor norms (see Propositions 2.1 and 3.1 in \cite{tensorproducts2002book}).

\item The solution $Y$ and its initial value $\xi$ both take their values in $\R^n$.

\item The collection of vector fields $\{f_1, \cdots, f_d\}$ on $\R^n$ are denoted by $f : \R^n\rightarrow L(\R^n, \R^d)$,
where $L(\R^n, \R^d)$ is the space of linear maps from $\R^n$ to $\R^d$. We will assume that $f$ has $Lip(\gamma)$ regularity with $\gamma > p$.
That is, the following norm is finite:
\begin{equation}
\|f\|_{Lip(\gamma)} := \max_{0 \leq k\leq \floor{\gamma}}\big\|D^k f\big\|_{\infty} \vee \big\|D^{\floor{\gamma}} f\big\|_{(\gamma - \floor{\gamma})-\text{H\"{o}l}}\,,
\label{eq:lipgamma}
\end{equation}
where $D^k f$ is the $k$-th (Fr\'{e}chet) derivative of $f$ and $\|\cdot\|_{\alpha\text{-H\"{o}l}}$ is the standard $\alpha$-H\"{o}lder norm for $\alpha\in(0,1)$.

\item The RDE (\ref{eq:RDE}) is defined in the Lyon's sense, so that by the Universal Limit Theorem
(see Theorem 5.3 in \cite{roughpath2007notes}), there exists a unique solution $Y : [0,T]\rightarrow\R^n$.
\end{itemize}

We define the log-ODE for approximating the solution $Y$ over an interval $[s,t]\subset [0,T]$ as follows: 
\begin{enumerate}
\item Compute the $\floor{\gamma}$-step log-signature of the control path $X$ over $[s,t]$. That is, we obtain $\log_{\floor{\gamma}}\big(S_{s,t}^{\floor{\gamma}}(X)\big) \in T^{\floor{\gamma}}(\R^d)$, where $\log_{\floor{\gamma}}(\cdot)$ is defined by projecting the standard tensor logarithm map onto $\{a\in T^{\floor{\gamma}}(\R^d) : \pi_0(a)>0\}$.

\item Construct the following (well-posed) ODE on the interval $[0,1]$,
\begin{align}
\frac{dz^{s,t}}{du} & := F\big(z^{s,t}\big),\label{eq:standardlogode}\\
z_0^{s,t} & := Y_s,\nonumber
\end{align}
where the vector field $F:\R^n\rightarrow\R^n$ is defined from the log-signature as
\begin{equation}
F(z) := \sum_{k=1}^{\floor{\gamma}}f^{\circ k}(z)\pi_k\Big(\log_{\floor{\gamma}}\big(S_{s,t}^{\floor{\gamma}}(X)\big)\Big).
\label{eq:logodevectfield}
\end{equation}
Recall that $f^{\circ k} : \R^n\rightarrow L((\R^d)^{\otimes k}, \R^n)$ was defined previously in Definition \ref{def:vect_derivative}.
\end{enumerate}
Then we can approximate $Y_t$ using the $u = 1$ solution of (\ref{eq:standardlogode}). Moreover, there exists a universal constant $C_{p,\gamma}$ depending only on $p$ and $\gamma$ such that 
\begin{equation}
\big\|Y_t - z_1^{s,t}\big\| \leq C_{p,\gamma}\|f\|_{Lip(\gamma)}^\gamma\|X\|_{p\text{-var};[s,t]}^\gamma,
\label{eq:local_logodeestimate}
\end{equation}
where $\|\cdot\|_{p\text{-var};[s,t]}$ is the $p$-variation norm defined for paths in $T^{\floor{p}}(\R^d)$ by
\begin{equation}
\|X\|_{p\text{-var};[s,t]} := \max_{1\leq k\leq \floor{p}}\sup_{\D}\bigg(\sum_{t_i\in\D}\big\|X_{t_i, t_{i+1}}^k\big\|^p\bigg)^\frac{1}{p},
\label{eq:rpnorm}
\end{equation}
with the supremum taken over all partitions $\D$ of $[s,t]$.
\end{theorem}\medbreak
\begin{remark}
If the vector fields $\{f_1, \cdots, f_d\}$ are linear, then it is a straightforward exercise to show that $F$ is linear.
\end{remark}

Although the above theorem requires some sophisticated theory, it has a simple conclusion - namely
that log-ODEs can approximate controlled differential equation. That said, the estimate (\ref{eq:local_logodeestimate}) does not directly apply when the vector fields $\{f_i\}$ are linear as they are unbounded. Fortunately, it is well known that solutions of linear RDEs exist and are unique.
\begin{theorem}[Theorem 10.57 in \cite{friz2010multidimensional}]\label{thm:linearexistance}
Consider the linear RDE on $[0,T]$
\begin{align*}
dY_t & = f(Y_t)\,dX_t,\\
Y_0 & = \xi,
\end{align*}
where $X$ is a geometric $p$-rough path in $\R^d$, $\xi\in\R^n$ and the vector fields $\{f_i\}_{1\leq i\leq d}$ take the form $f_i(y) = A_i y + B$ where $\{A_{i}\}$ and $\{B_i\}$ are $n\times n$ matrices. Let $K$ denote an upper bound on $\max_i (\|A_i\| + \|B_i\|)$. Then a unique solution $Y:[0,T]\rightarrow\R^n$ exists. Moreover, it is bounded and there exists a constant $C_p$ depending only on $p$ such that
\begin{equation}
\|Y_t - Y_s\| \leq C_p\big(1+\|\xi\|\big)K\|X\|_{p\text{-var};[s,t]}\exp\Big(C_p K^p \|X\|_{p\text{-var};[s,t]}^p\Big),
\label{eq:linearRDEbound}
\end{equation}
for all $0\leq s\leq t\leq T$.
\end{theorem}

When the vector fields of the RDE (\ref{eq:RDE}) are linear, then the log-ODE (\ref{eq:standardlogode}) also becomes linear. Therefore, the log-ODE solution exists and is explicitly given as the exponential of the matrix $F$.

\begin{theorem}
Consider the same linear RDE on $[0,T]$ as in Theorem \ref{thm:linearexistance},
\begin{align*}
dY_t & = f(Y_t)\,dX_t,\\
Y_0 & = \xi.\nonumber
\end{align*}
Then the log-ODE vector field $F$ given by (\ref{eq:logodevectfield}) is linear and the solution of the associated ODE (\ref{eq:standardlogode}) exists and satisfies
\begin{equation}
\|z_u^{s,t}\| \leq \|Y_s\|\exp\bigg(\sum_{m=1}^{\floor{\gamma}}K^m \Big\|\pi_m\Big(\log_{\floor{\gamma}}\big(S_{s,t}^{\floor{\gamma}}(X)\big)\Big)\Big\|\bigg),
\label{eq:linearODEbound}
\end{equation}
for $u\in[0,1]$ and all $0\leq s\leq t\leq T$.
\end{theorem}
\begin{proof}
Since $F$ is a linear vector field on $\R^n$, we can view it as an $n\times n$ matrix and so for $u\in[0,1]$,
\begin{equation}
z_u^{s,t} = \exp(uF)z_0^{s,t},\nonumber
\end{equation}

where $\exp$ denotes the matrix exponential. The result now follows by the standard estimate $\|\exp(F)\| \leq \exp(\|F\|)$.
\end{proof}
\begin{remark}\label{rmk:linear_rmk}
By the boundedness of linear RDEs (\ref{eq:linearRDEbound}) and log-ODEs (\ref{eq:linearODEbound}), the arguments that established Theorem \ref{thm:logODEthm} hold in the linear case as $\|f\|_{Lip(\gamma)}$ would be finite when defined using the domains that the solutions $Y$ and $z$ lie in.
\end{remark}

Given the local error estimate (\ref{eq:local_logodeestimate}) for the log-ODE method, we can now consider the approximation error that is exhibited by a log-ODE numerical solution to the RDE (\ref{eq:RDE}). Fortunately, the analysis required to derive such global error estimates was developed by Greg Gyurk\'{o} in his PhD thesis. 
Thus, the following result is a straightforward application of Theorem 3.2.1 from \cite{gyurko2008thesis}.\medbreak

\begin{theorem} Let $X$, $f$ and $Y$ satisfy the assumptions given by Theorem \ref{thm:logODEthm} and suppose that $\{0 = t_0 < t_1 < \cdots < t_N = T\}$ is a partition of $[0,T]$ with $\max_{\,k}\|X\|_{p\text{-var};[t_k,t_{k+1}]}$ sufficiently small. We can construct a numerical solution $\{Y_k^{Log}\}_{0\leq k \leq N}$ of (\ref{eq:RDE}) by setting $Y_0^{Log} := Y_0$ and for each $k \in \{0, 1, \cdots, N - 1\}$, defining $Y_{k+1}^{Log}$ to be the solution at $u=1$ of the following ODE:
\begin{align}
\frac{dz^{t_k,t_{k+1}}}{du} & := F\big(z^{t_k,t_{k+1}}\big),\label{eq:standardlogode2}\\
z_0^{t_k,t_{k+1}} & := Y_k^{Log},\nonumber
\end{align}
where the vector field $F$ is constructed from the log-signature of $X$ over the interval $[t_k, t_{k+1}]$ according to (\ref{eq:logodevectfield}). Then there exists a constant $C$ depending only on $p$, $\gamma$ and $\|f\|_{Lip(\gamma)}$ such that
\begin{equation}
\big\|Y_{t_k} - Y_k^{Log}\big\| \leq C\sum_{i=0}^{k-1}\|X\|_{p\text{-var};[t_i,t_{i+1}]}^\gamma,
\label{eq:global_logodeestimate}
\end{equation}
for $0\leq k\leq N$.
\end{theorem}
\begin{remark}
The above error estimate also holds when the vector field $f$ is linear (by Remark \ref{rmk:linear_rmk})).
\end{remark}

Since $\floor{\gamma}$ is the truncation depth of the log-signatures used to construct each log-ODE vector field, we see that high convergence rates can be achieved through using more terms in each log-signature.
It is also unsurprising that the error estimate (\ref{eq:global_logodeestimate}) increases with the ``roughness'' of the control path.
So just as in our experiments, we see that the performance of the log-ODE method can be improved by choosing an appropriate step size and depth of log-signature.
