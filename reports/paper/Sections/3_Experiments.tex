\section{Experiments} \label{sec:experiments}
We investigate solving a Neural CDE with and without the log-ODE method on four real-world problems. Every problem was chosen for its long length. The lengths are in fact sufficiently long that adjoint-based backpropagation was used to avoid running out of memory at any reasonable batch size.

Every problem is regularly sampled, so we take $t_i = i$.

We will denote a Neural CDE model with log-ODE method, using depth $N$ and step $s$, as $\mathrm{NCDE}^s_N$. Taking $N=1$ corresponds to not using the log-ODE method as per Section \ref{subsec:tradeoff}, with data subsampled at rate $1/s$. Thus we use $\mathrm{NCDE}^1_1$ as our benchmark: no subsampling, no log-ODE method.

Each model is run three times and we report the mean and standard deviation of the test metrics along with the mean training times and memory usages. 

For each task, the hyperparameters were selected by performing a grid search on the $\mathrm{NCDE}^s_1$ model, where $s$ was chosen so that the length of the sequence was 500 steps. This was found to create a reasonable balance between training time and sequence length. (Doing hyperoptimisation on the baseline $\mathrm{NCDE}_1^1$ model would have been more difficult due to the larger training times.) 

%These hidden layer sizes were then used for the corresponding NCDE$^s_{1, 2, 3}$ models for each step length $s = 2^l, \; l \in \{0, 1, 2,..., 9\}$.

Precise details of the experiments can be found in Appendices \ref{apx:experiments} and \ref{apx:results}.

\subsection{Classification with EigenWorms}
Our first example uses the EigenWorms dataset from the UEA archive from \cite{bagnall16bakeoff}. This consists of time series of length 17,984 and 6 channels, corresponding to the movement of a roundworm. The goal is to classify each worm as either wild-type or one of four mutant-type classes.

\begin{figure}
    \centering
    \includegraphics[width=0.95\textwidth]{Images/eigenworms.png}
    \caption{\textbf{Left:} Heatmap of accuracies on the EigenWorms dataset for differing step sizes and depths. \textbf{Right:} Log-log plot of the elapsed time of the algorithm against the step size.}
    \label{fig:eigenworms}
\end{figure}

\input{Tables/eignworms}

See Table \ref{tab:eigenworms}. We see that the straightforward $\mathrm{NCDE}^1_1$ model takes roughly a day to train. Using the log-ODE method ($\mathrm{NCDE}_2$, $\mathrm{NCDE}_3$) speeds this up to take roughly minutes. Doing so additionally improves model performance dramatically, and reduces memory usage. Naive subsampling approaches ($\mathrm{NCDE}^{8}_1$, $\mathrm{NCDE}^{32}_1$, $\mathrm{NCDE}^{128}_1$) only achieve speedups without performance improvements.

See also Figure \ref{fig:eigenworms}, in which we summarise results for a larger range of step sizes.

\subsection{Estimating Vitals Signs from PPG and ECG Data}
Next we consider the problem of estimating vital signs from PPG and ECG data. The data is taken from the TSR archive \cite{MonashTSRegressionArchive} and involves data from the Beth Israel Deaconess Medical Centre (BIDMC). We consider three tasks whereby we aim to predict a persons respiratory rate (RR), their heart rate (HR), and their oxygen saturation (SpO2). This data is sampled at 125hZ with each series having a length of 4000, 7949 training samples, and a dimension of 3 (including time).

We train a model on each of the three vitals sign prediction tasks using a similar approach to the EigenWorms dataset. The metric used to evaluate performance is the root mean squared error (RMSE) loss which is the standard loss considered in the TSR archive. The results over a range of step sizes are presented in table (\ref{tab:bidmc}). The full results over all step sizes, along with a plots analogous to figure \ref{fig:eigenworms} are left to Appendix \ref{apx:results}.

\input{Tables/bidmc}

We find that the depth $3$ model is the top performer for every task at any step size. Whats more, the top performing depth 3 model from each category also significantly outperforms the NCDE$^1_1$ model with a significantly reduced training time. This again illustrates that the increased step size not only reduces training time, but can also improve model performance. We believe this is attributable to the log-ODE model being better at learning these long-term dependencies, as the worst scores of the NCDE$^s_{2, 3}$ models are with step sizes 2 and 4 for all tasks where they are on par (or worse) than the corresponding depth 1 model.

Both experiments give show that the depth 2 and 3 models can not only reduce training times with similar levels of performance, but can additionally result in improved performance over these large steps. 
